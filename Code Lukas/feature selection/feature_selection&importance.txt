RFE NOTES

Warum verläuft die Kurve so ungewöhnlich? Warum der Starke Drop in RSME hin zu 51 Features?

Müssten wir statt auf Checkout Amount auf eine transformierte Zielvariable modeln, die das Treatment enthält (siehe Gubelas Z-Transformation), und dafür auf Treatment in den independent variables verzichten?
Wären die Ergebnisse dann besser/klarer?


Warum ist das R-Squared so niedrig?

Bsp.
print(fa_rfe)

Recursive feature selection

Outer resampling method: Cross-Validated (5 fold) 

Resampling performance over subset size:

 Variables		RMSE		Rsquared		MAE		RMSESD		RsquaredSD 	MAESD Selected
         5		27.77 		0.006951 		9.580  	2.266   		0.004528 		0.2156         
         6 		27.98 		0.005674 		9.633  	2.248 		0.002927 		0.1826         
         8 		27.84 		0.008693 		9.618  	2.252   		0.002924 		0.1833         
        10		27.91 		0.011502 		9.746  	2.182   		0.003659 		0.2124         
        12 		27.91 		0.014594 		9.828  	2.160   		0.007001 		0.2246         
        15 		27.78 		0.021386 		9.762  	2.217   		0.010634 		0.1711         
        51 		27.12 		0.062283 		9.459  	1.968   		0.011832 		0.2054        *

SOURCES:
#http://topepo.github.io/caret/recursive-feature-elimination.html#rfe
#https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/
#https://stackoverflow.com/questions/32290513/making-recursive-feature-elimination-using-caret-parallel-on-windows


CODE EXECUTED FOR FA RFE
> cl <- makeCluster(8, type='PSOCK')
> registerDoParallel(cl)
> subsets <- c(5,6,8,10,12,15)
> set.seed(123)
> seeds <- vector(mode = "list", length = 6)
> for(i in 1:5) seeds[[i]] <- sample.int(1000, length(subsets) + 1)
> seeds[[6]] <- sample.int(1000, 1)
> # load the data
> # define the control using a random forest selection function
> control <- rfeControl(functions=rfFuncs, method="cv", number=5, seeds=seeds, saveDetails = TRUE)
> # run the RFE algorithm
> set.seed(1)
> system.time(rfe_f_a.results_new <- rfe(trainData_f_a2[,-c(1,2)], trainData_f_a2[,1], sizes=subsets, rfeControl=control))


CODE EXECUTED FOR FB RFE
> cl <- makeCluster(8, type='PSOCK')
> registerDoParallel(cl)
> subsets <- c(5,6,8,10,12,15)
> set.seed(123)
> seeds <- vector(mode = "list", length = 6)
> for(i in 1:5) seeds[[i]] <- sample.int(1000, length(subsets) + 1)
> seeds[[6]] <- sample.int(1000, 1)
> # load the data
> # define the control using a random forest selection function
> control <- rfeControl(functions=rfFuncs, method="cv", number=5, seeds=seeds, saveDetails = TRUE)
> # run the RFE algorithm
> set.seed(1)
> system.time(rfe_f_b.results <- rfe(trainData_f_b2[,-c(1,2)], trainData_f_b2[,1], sizes=subsets, rfeControl=control))


CODE EXECUTED FOR BT RFE
> subsets <- c(5,6,8,10,12,15)
> set.seed(1)
> stopCluster(cl)
> library(doParallel)
> cl <- makeCluster(detectCores()-8, type='PSOCK')
> registerDoParallel(cl)
> set.seed(123)
> seeds <- vector(mode = "list", length = 6)
> for(i in 1:5) seeds[[i]] <- sample.int(1000, length(subsets) + 1)
> seeds[[6]] <- sample.int(1000, 1)
> # load the data
> # define the control using a random forest selection function
> control <- rfeControl(functions=rfFuncs, method="cv", number=5, seeds=seeds, saveDetails = TRUE)
> #control <- rfeControl(functions=lmFuncs, method="cv", number=10)
> subsets <- c(5,6,8,10,12,15)
> # run the RFE algorithm
> set.seed(1)
> system.time(rfe_b_t.results <- rfe(trainData_b_t[,-c(1,2)], trainData_b_t[,1], sizes=subsets, rfeControl=control))